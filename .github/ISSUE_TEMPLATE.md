---
title: 最新论文 - 2025年01月27日
labels: documentation
---
## 最后更新：2025-01-27 09:16
**本次更新执行命令**
```
target\debug\my_auto_papers.exe --keywords=
             efficient RL,video super resolution,
             partial observable markov decision process/pomdp,sparse reward reinforcement learning,
             2.5d fighting game/fighting game ai/game ai/fighting game reinforcement learning,
             combinatorial game theory/xiangqi/chinese chess,
             code llm,
             speech recognition,
             zero shot tracking/few shot tracking/pose tracking/pose estimation,
             text to 3d/image to 3d/text to texture,
             casual inference,
             automated theorem proving/interactive theorem proving/formal verification
              --exclude-keywords=multi-agent --per-keyword-max-result=50
```

**参数详解**
- 关键词：`efficient RL`, `video super resolution`, `partial observable markov decision process/pomdp`, `sparse reward reinforcement learning`, `2.5d fighting game/fighting game ai/game ai/fighting game reinforcement learning`, `combinatorial game theory/xiangqi/chinese chess`, `code llm`, `speech recognition`, `zero shot tracking/few shot tracking/pose tracking/pose estimation`, `text to 3d/image to 3d/text to texture`, `casual inference`, `automated theorem proving/interactive theorem proving/formal verification`
- 排除关键词：`multi-agent`
- 每关键词最大结果：`50`
- 目标领域：`cs`, `stat`
- 每关键词重试次数：`3`


## 论文汇总（0篇）

**更好的阅读体验请访问 [Github页面](https://github.com/dbsxdbsx/MyDailyPaper)。**


### 1. efficient RL
| **序号** | **标题** | **日期** |
| --- | --- | --- |
| **1** | **[Adaptive Data Exploitation in Deep Reinforcement Learning](http://arxiv.org/abs/2501.12620v1)** | 2025-01-22 |
| **2** | **[SLIM: Sim-to-Real Legged Instructive Manipulation via Long-Horizon Visuomotor Learning](http://arxiv.org/abs/2501.09905v2)** | 2025-01-17 |
| **3** | **[Overcoming the Curse of Dimensionality in Reinforcement Learning Through Approximate Factorization](http://arxiv.org/abs/2411.07591v1)** | 2024-11-12 |
| **4** | **[Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning](http://arxiv.org/abs/2410.21845v2)** | 2024-10-29 |
| **5** | **[On-Robot Reinforcement Learning with Goal-Contrastive Rewards](http://arxiv.org/abs/2410.19989v1)** | 2024-10-25 |
| **6** | **[Uncovering RL Integration in SSL Loss: Objective-Specific Implications for Data-Efficient RL](http://arxiv.org/abs/2410.17428v1)** | 2024-10-22 |
| **7** | **[EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data](http://arxiv.org/abs/2403.00564v2)** | 2024-03-01 |
| **8** | **[Brain-Like Replay Naturally Emerges in Reinforcement Learning Agents](http://arxiv.org/abs/2402.01467v2)** | 2024-02-02 |
| **9** | **[RL$^3$: Boosting Meta Reinforcement Learning via RL inside RL$^2$](http://arxiv.org/abs/2306.15909v5)** | 2023-06-28 |
| **10** | **[Model-Based Reinforcement Learning with Multinomial Logistic Function Approximation](http://arxiv.org/abs/2212.13540v2)** | 2022-12-27 |
### 2. video super resolution
| **序号** | **标题** | **日期** |
| --- | --- | --- |
| **1** | **[BF-STVSR: B-Splines and Fourier-Best Friends for High Fidelity Spatial-Temporal Video Super-Resolution](http://arxiv.org/abs/2501.11043v1)** | 2025-01-19 |
| **2** | **[DiffVSR: Enhancing Real-World Video Super-Resolution with Diffusion Models for Advanced Visual Quality and Temporal Consistency](http://arxiv.org/abs/2501.10110v2)** | 2025-01-17 |
| **3** | **[STAR: Spatial-Temporal Augmentation with Text-to-Video Models for Real-World Video Super-Resolution](http://arxiv.org/abs/2501.02976v1)** | 2025-01-06 |
| **4** | **[Compressed Domain Prior-Guided Video Super-Resolution for Cloud Gaming Content](http://arxiv.org/abs/2501.01773v1)** | 2025-01-03 |
| **5** | **[Sequence Matters: Harnessing Video Models in 3D Super-Resolution](http://arxiv.org/abs/2412.11525v3)** | 2024-12-16 |
| **6** | **[A Plug-and-Play Algorithm for 3D Video Super-Resolution of Single-Photon LiDAR data](http://arxiv.org/abs/2412.09427v1)** | 2024-12-12 |
| **7** | **[RTSR: A Real-Time Super-Resolution Model for AV1 Compressed Content](http://arxiv.org/abs/2411.13362v1)** | 2024-11-20 |
| **8** | **[360-Degree Video Super Resolution and Quality Enhancement Challenge: Methods and Results](http://arxiv.org/abs/2411.06738v1)** | 2024-11-11 |
| **9** | **[SeeClear: Semantic Distillation Enhances Pixel Condensation for Video Super-Resolution](http://arxiv.org/abs/2410.05799v4)** | 2024-10-08 |
| **10** | **[Enhancing Space-time Video Super-resolution via Spatial-temporal Feature Interaction](http://arxiv.org/abs/2207.08960v4)** | 2022-07-18 |
### 3. partial observable markov decision process/pomdp
| **序号** | **标题** | **日期** |
| --- | --- | --- |
| **1** | **[Online Hybrid-Belief POMDP with Coupled Semantic-Geometric Models and Semantic Safety Awareness](http://arxiv.org/abs/2501.11202v1)** | 2025-01-20 |
| **2** | **[Microservice Deployment in Space Computing Power Networks via Robust Reinforcement Learning](http://arxiv.org/abs/2501.06244v1)** | 2025-01-08 |
| **3** | **[A New Interpretation of the Certainty-Equivalence Approach for PAC Reinforcement Learning with a Generative Model](http://arxiv.org/abs/2501.02652v1)** | 2025-01-05 |
| **4** | **[Partially Observed Optimal Stochastic Control: Regularity, Optimality, Approximations, and Learning](http://arxiv.org/abs/2412.06735v2)** | 2024-12-09 |
| **5** | **[Hierarchical Object-Oriented POMDP Planning for Object Rearrangement](http://arxiv.org/abs/2412.01348v2)** | 2024-12-02 |
| **6** | **[Near Optimal Approximations and Finite Memory Policies for POMPDs with Continuous Spaces](http://arxiv.org/abs/2410.02895v2)** | 2024-10-03 |
| **7** | **[Reward Machines for Deep RL in Noisy and Uncertain Environments](http://arxiv.org/abs/2406.00120v4)** | 2024-05-31 |
| **8** | **[AutoMix: Automatically Mixing Language Models](http://arxiv.org/abs/2310.12963v5)** | 2023-10-19 |
| **9** | **[Experimental Study on The Effect of Multi-step Deep Reinforcement Learning in POMDPs](http://arxiv.org/abs/2209.04999v2)** | 2022-09-12 |
### 4. sparse reward reinforcement learning
| **序号** | **标题** | **日期** |
| --- | --- | --- |
| **1** | **[Dense Dynamics-Aware Reward Synthesis: Integrating Prior Experience with Demonstrations](http://arxiv.org/abs/2412.01114v1)** | 2024-12-02 |
| **2** | **[Subwords as Skills: Tokenization for Sparse-Reward Reinforcement Learning](http://arxiv.org/abs/2309.04459v2)** | 2023-09-08 |
| **3** | **[Language Reward Modulation for Pretraining Reinforcement Learning](http://arxiv.org/abs/2308.12270v1)** | 2023-08-23 |
| **4** | **[Exploiting Transformer in Sparse Reward Reinforcement Learning for Interpretable Temporal Logic Motion Planning](http://dx.doi.org/10.1109/LRA.2023.3290511)** | 2022-09-27 |
| **5** | **[A Cooperation Graph Approach for Multiagent Sparse Reward Reinforcement Learning](http://arxiv.org/abs/2208.03002v1)** | 2022-08-05 |
| **6** | **[Abstract Demonstrations and Adaptive Exploration for Efficient and Stable Multi-step Sparse Reward Reinforcement Learning](http://dx.doi.org/10.1109/ICAC55051.2022.9911100)** | 2022-07-19 |
| **7** | **[Potential-based Reward Shaping in Sokoban](http://arxiv.org/abs/2109.05022v1)** | 2021-09-10 |
| **8** | **[Touch-based Curiosity for Sparse-Reward Tasks](http://arxiv.org/abs/2104.00442v2)** | 2021-04-01 |
| **9** | **[Ask Your Humans: Using Human Instructions to Improve Generalization in Reinforcement Learning](http://arxiv.org/abs/2011.00517v3)** | 2020-11-01 |
| **10** | **[Long-Term Visitation Value for Deep Exploration in Sparse Reward Reinforcement Learning](http://dx.doi.org/10.3390/a15030081)** | 2020-01-01 |
### 5. 2.5d fighting game/fighting game ai/game ai/fighting game reinforcement learning
| **序号** | **标题** | **日期** |
| --- | --- | --- |
| **1** | **[RL-LLM-DT: An Automatic Decision Tree Generation Method Based on RL Evaluation and LLM Enhancement](http://arxiv.org/abs/2412.11417v2)** | 2024-12-16 |
| **2** | **[Training Interactive Agent in Large FPS Game Map with Rule-enhanced Reinforcement Learning](http://arxiv.org/abs/2410.04936v1)** | 2024-10-07 |
| **3** | **[You Have Thirteen Hours in Which to Solve the Labyrinth: Enhancing AI Game Masters with Function Calling](http://arxiv.org/abs/2409.06949v1)** | 2024-09-11 |
| **4** | **[Enhancing Dialogue Generation in Werewolf Game Through Situation Analysis and Persuasion Strategies](http://arxiv.org/abs/2408.16586v2)** | 2024-08-29 |
| **5** | **[Personalized Dynamic Difficulty Adjustment -- Imitation Learning Meets Reinforcement Learning](http://arxiv.org/abs/2408.06818v1)** | 2024-08-13 |
| **6** | **[Strategy Game-Playing with Size-Constrained State Abstraction](http://arxiv.org/abs/2408.06202v1)** | 2024-08-12 |
| **7** | **[Learning With Generalised Card Representations for "Magic: The Gathering"](http://arxiv.org/abs/2407.05879v1)** | 2024-07-08 |
| **8** | **[Injecting Combinatorial Optimization into MCTS: Application to the Board Game boop](http://arxiv.org/abs/2406.08766v1)** | 2024-06-13 |
| **9** | **[ChatPCG: Large Language Model-Driven Reward Design for Procedural Content Generation](http://arxiv.org/abs/2406.11875v1)** | 2024-06-07 |
| **10** | **[An Interactive Agent Foundation Model](http://arxiv.org/abs/2402.05929v2)** | 2024-02-08 |
| **11** | **[Diversity-based Deep Reinforcement Learning Towards Multidimensional Difficulty for Fighting Game AI](http://arxiv.org/abs/2211.02759v1)** | 2022-11-04 |
| **12** | **[Identification of Play Styles in Universal Fighting Engine](http://arxiv.org/abs/2108.03599v1)** | 2021-08-08 |
| **13** | **[Introduction to Behavior Algorithms for Fighting Games](http://dx.doi.org/10.1109/CHILECON47746.2019.8988008)** | 2020-07-06 |
| **14** | **[Enhanced Rolling Horizon Evolution Algorithm with Opponent Model Learning: Results for the Fighting Game AI Competition](http://arxiv.org/abs/2003.13949v1)** | 2020-03-31 |
| **15** | **[Deep Reinforcement Learning for Playing 2.5D Fighting Games](http://arxiv.org/abs/1805.02070v1)** | 2018-05-05 |
